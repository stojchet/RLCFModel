max_seq_length: 150
language: python
dataset_size: 10
epochs: 1
per_device_train_batch_size: 8
gradient_accumulation_steps: 16
learning_rate: 1.41e-5
lora_r: 64
lora_alpha: 16
lora_dropout: 0.05
warmup_ratio: 0.2
dataset_name: stojchet/kto-deepseek-coder-1.3b-base-empty-fn
base_model: deepseek-ai/deepseek-coder-1.3b-base